import os
import os.path as osp
import csv
from collections import defaultdict, OrderedDict


def get_run_size_from_filename(filename):
    # bubble_a_1000.csv -> bubble_a_1000
    run_name = osp.splitext(filename)[0]

    # bubble_a_1000 -> 1000
    run_size = int(run_name.rsplit('_', 1)[1])

    return run_size


def get_avg_stddev(folder, filename):
    filename = osp.join(folder, filename)

    with open(filename) as csv_file:
        file_rows = csv.reader(csv_file, delimiter=',')

        for rr in file_rows:
            row_size = len(rr)
            csv_file.close()
            return rr[row_size-2], rr[row_size-1]


if __name__ == '__main__':
    # OBS: This program trusts that you're using it with the reports generated by the runner utility.

    reports_dir = osp.join(os.getcwd(), 'reports')
    filenames = os.listdir(reports_dir)

    runs = defaultdict(list)

    # discovering reports file names
    for filename in filenames:
        # bubble_a_1000.csv -> bubble_a_1000
        run_name = osp.splitext(filename)[0]
        # bubble_a_1000 -> bubble_a
        algorithm_name = run_name.rsplit('_', 1)[0]

        runs[algorithm_name].append(filename)

    # sorting runs in ascending order by batch size
    for algorithm in runs.keys():
        runs[algorithm] = sorted(runs[algorithm], key=lambda x: get_run_size_from_filename(x))

    # compiling average and std_dev for each algorithm execution mode
    execution_statistics = defaultdict(dict)

    for algorithm, filenames in runs.items():
        sizes = [get_run_size_from_filename(filename) for filename in filenames]

        average_time = list()
        devs = list()

        for filename in filenames:
            # run_size = get_run_size_from_filename(filename)
            avg, stddev = get_avg_stddev(reports_dir, filename)

            average_time.append(avg)
            devs.append(stddev)

        data = {'size': sizes, 'average_time': average_time, 'std_dev': devs}

        # quick_a -> [quick, a]
        algo_name, mode = algorithm.rsplit('_', 1)

        # storing everything into the lookup table
        execution_statistics[algo_name][mode] = data

    # writing execution summary into a separate CSV file.
    subtitle = {'r': 'random', 'a': 'ascending', 'd': 'descending'}
    with open('summary.csv', 'w') as file:
        csv_writer = csv.writer(file, delimiter=',')

        for algorithm, statistics in execution_statistics.items():
            for mode, statistic in statistics.items():

                header = '%s - %s' % (algorithm, subtitle[mode])
                csv_writer.writerow([header])

                csv_writer.writerow(statistic['size'])
                csv_writer.writerow(statistic['average_time'])
                csv_writer.writerow(statistic['std_dev'])
                csv_writer.writerow(list())
        file.close()

